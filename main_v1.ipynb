{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup_mnist.py -- mnist data and model loading code\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import urllib.request\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(num_images*28*28)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data / 255) - 0.5\n",
    "        data = data.reshape(num_images, 28, 28, 1)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "    return (np.arange(10) == labels[:, None]).astype(np.float32)\n",
    "\n",
    "class MNIST:\n",
    "    def __init__(self):\n",
    "        if not os.path.exists(\"data\"):\n",
    "            os.mkdir(\"data\")\n",
    "            files = [\"train-images-idx3-ubyte.gz\",\n",
    "                     \"t10k-images-idx3-ubyte.gz\",\n",
    "                     \"train-labels-idx1-ubyte.gz\",\n",
    "                     \"t10k-labels-idx1-ubyte.gz\"]\n",
    "            for name in files:\n",
    "\n",
    "                urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/' + name, \"data/\"+name)\n",
    "\n",
    "        train_data = extract_data(\"data/train-images-idx3-ubyte.gz\", 60000)\n",
    "        train_labels = extract_labels(\"data/train-labels-idx1-ubyte.gz\", 60000)\n",
    "        self.test_data = extract_data(\"data/t10k-images-idx3-ubyte.gz\", 10000)\n",
    "        self.test_labels = extract_labels(\"data/t10k-labels-idx1-ubyte.gz\", 10000)\n",
    "        \n",
    "        VALIDATION_SIZE = 5000\n",
    "        \n",
    "        self.validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "        self.validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "        self.train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "        self.train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "\n",
    "class MNISTModel:\n",
    "    def __init__(self, restore, session=None):\n",
    "        self.num_channels = 1\n",
    "        self.image_size = 28\n",
    "        self.num_labels = 10\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, (3, 3),\n",
    "                         input_shape=(28, 28, 1)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(10))\n",
    "        model.load_weights(restore)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_models.py -- train the neural network models for attacking\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "#from setup_mnist import MNIST\n",
    "#from setup_cifar import CIFAR\n",
    "import os\n",
    "\n",
    "def train(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
    "    \"\"\"\n",
    "    Standard neural network training procedure.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    print(data.train_data.shape)\n",
    "    \n",
    "    model.add(Conv2D(params[0], (3, 3),\n",
    "                            input_shape=data.train_data.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[1], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(params[2], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(params[3], (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(params[4]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(params[5]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    \n",
    "    if init != None:\n",
    "        model.load_weights(init)\n",
    "\n",
    "    def fn(correct, predicted):\n",
    "        return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                       logits=predicted/train_temp)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "\n",
    "    if file_name != None:\n",
    "        model.save(file_name)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_distillation(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1):\n",
    "    \"\"\"\n",
    "    Train a network using defensive distillation.\n",
    "\n",
    "    Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks\n",
    "    Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, Ananthram Swami\n",
    "    IEEE S&P, 2016.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_name+\"_init\"):\n",
    "        # Train for one epoch to get a good starting point.\n",
    "        train(data, file_name+\"_init\", params, 1, batch_size)\n",
    "    \n",
    "    # now train the teacher at the given temperature\n",
    "    teacher = train(data, file_name+\"_teacher\", params, num_epochs, batch_size, train_temp,\n",
    "                    init=file_name+\"_init\")\n",
    "\n",
    "    # evaluate the labels at temperature t\n",
    "    predicted = teacher.predict(data.train_data)\n",
    "    with tf.Session() as sess:\n",
    "        y = sess.run(tf.nn.softmax(predicted/train_temp))\n",
    "        print(y)\n",
    "        data.train_labels = y\n",
    "\n",
    "    # train the student model at temperature t\n",
    "    student = train(data, file_name, params, num_epochs, batch_size, train_temp,\n",
    "                    init=file_name+\"_init\")\n",
    "\n",
    "    # and finally we predict at temperature 1\n",
    "    predicted = student.predict(data.train_data)\n",
    "\n",
    "    print(predicted)\n",
    "    \n",
    "if not os.path.isdir('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "#train(CIFAR(), \"models/cifar\", [64, 64, 128, 128, 256, 256], num_epochs=50)\n",
    "train(MNIST(), \"models/mnist\", [32, 32, 64, 64, 200, 200], num_epochs=50)\n",
    "\n",
    "#train_distillation(MNIST(), \"models/mnist-distilled-100\", [32, 32, 64, 64, 200, 200], num_epochs=50, train_temp=100)\n",
    "#train_distillation(CIFAR(), \"models/cifar-distilled-100\", [64, 64, 128, 128, 256, 256],num_epochs=50, train_temp=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## verify.py -- check the accuracy of a neural network\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "#from setup_cifar import CIFAR, CIFARModel\n",
    "#from setup_mnist import MNIST, MNISTModel\n",
    "#from setup_inception import ImageNet, InceptionModel\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    data, model = MNIST(), MNISTModel(\"models/mnist\", sess)\n",
    "    #data, model = CIFAR(), CIFARModel(\"models/cifar\", sess)\n",
    "    #data, model = ImageNet(), InceptionModel(sess)\n",
    "\n",
    "    x = tf.placeholder(tf.float32, (None, model.image_size, model.image_size, model.num_channels))\n",
    "    y = model.predict(x)\n",
    "\n",
    "    r = []\n",
    "    for i in range(0,len(data.test_data),BATCH_SIZE):\n",
    "        pred = sess.run(y, {x: data.test_data[i:i+BATCH_SIZE]})\n",
    "        #print(pred)\n",
    "        #print('real',data.test_labels[i],'pred',np.argmax(pred))\n",
    "        r.append(np.argmax(pred,1) == np.argmax(data.test_labels[i:i+BATCH_SIZE],1))\n",
    "        print('mean: ',np.mean(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## l2_attack.py -- attack a network optimizing for l_2 distance\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "BINARY_SEARCH_STEPS = 9  # number of times to adjust the constant with binary search\n",
    "MAX_ITERATIONS = 10000   # number of iterations to perform gradient descent\n",
    "ABORT_EARLY = True       # if we stop improving, abort gradient descent early\n",
    "LEARNING_RATE = 1e-2     # larger values converge faster to less accurate results\n",
    "TARGETED = True          # should we target one specific class? or just be wrong?\n",
    "CONFIDENCE = 0           # how strong the adversarial example should be\n",
    "INITIAL_CONST = 1e-3     # the initial constant c to pick as a first guess\n",
    "\n",
    "class CarliniL2:\n",
    "    def __init__(self, sess, model, batch_size=1, confidence = CONFIDENCE,\n",
    "                 targeted = TARGETED, learning_rate = LEARNING_RATE,\n",
    "                 binary_search_steps = BINARY_SEARCH_STEPS, max_iterations = MAX_ITERATIONS,\n",
    "                 abort_early = ABORT_EARLY, \n",
    "                 initial_const = INITIAL_CONST,\n",
    "                 boxmin = -0.5, boxmax = 0.5):\n",
    "        \"\"\"\n",
    "        The L_2 optimized attack. \n",
    "\n",
    "        This attack is the most efficient and should be used as the primary \n",
    "        attack to evaluate potential defenses.\n",
    "\n",
    "        Returns adversarial examples for the supplied model.\n",
    "\n",
    "        - confidence: Confidence of adversarial examples: higher produces examples\n",
    "          that are farther away, but more strongly classified as adversarial.\n",
    "        - batch_size: Number of attacks to run simultaneously.\n",
    "          targeted: True if we should perform a targetted attack, False otherwise.\n",
    "        - learning_rate: The learning rate for the attack algorithm. Smaller values\n",
    "          produce better results but are slower to converge.\n",
    "        - binary_search_steps: The number of times we perform binary search to\n",
    "          find the optimal tradeoff-constant between distance and confidence. \n",
    "        - max_iterations: The maximum number of iterations. Larger values are more\n",
    "          accurate; setting too small will require a large learning rate and will\n",
    "          produce poor results.\n",
    "        - abort_early: If true, allows early aborts if gradient descent gets stuck.\n",
    "        - initial_const: The initial tradeoff-constant to use to tune the relative\n",
    "          importance of distance and confidence. If binary_search_steps is large,\n",
    "          the initial constant is not important.\n",
    "        - boxmin: Minimum pixel value (default -0.5).\n",
    "        - boxmax: Maximum pixel value (default 0.5).\n",
    "        \"\"\"\n",
    "\n",
    "        image_size, num_channels, num_labels = model.image_size, model.num_channels, model.num_labels\n",
    "        self.sess = sess\n",
    "        self.TARGETED = targeted\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.MAX_ITERATIONS = max_iterations\n",
    "        self.BINARY_SEARCH_STEPS = binary_search_steps\n",
    "        self.ABORT_EARLY = abort_early\n",
    "        self.CONFIDENCE = confidence\n",
    "        self.initial_const = initial_const\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.repeat = binary_search_steps >= 10\n",
    "\n",
    "        self.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK = False\n",
    "\n",
    "        shape = (batch_size,image_size,image_size,num_channels)\n",
    "        \n",
    "        # the variable we're going to optimize over\n",
    "        modifier = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "\n",
    "        # these are variables to be more efficient in sending data to tf\n",
    "        self.timg = tf.Variable(np.zeros(shape), dtype=tf.float32)\n",
    "        self.tlab = tf.Variable(np.zeros((batch_size,num_labels)), dtype=tf.float32)\n",
    "        self.const = tf.Variable(np.zeros(batch_size), dtype=tf.float32)\n",
    "\n",
    "        # and here's what we use to assign them\n",
    "        self.assign_timg = tf.placeholder(tf.float32, shape)\n",
    "        self.assign_tlab = tf.placeholder(tf.float32, (batch_size,num_labels))\n",
    "        self.assign_const = tf.placeholder(tf.float32, [batch_size])\n",
    "        \n",
    "        # the resulting image, tanh'd to keep bounded from boxmin to boxmax\n",
    "        self.boxmul = (boxmax - boxmin) / 2.\n",
    "        self.boxplus = (boxmin + boxmax) / 2.\n",
    "        self.newimg = tf.tanh(modifier + self.timg) * self.boxmul + self.boxplus\n",
    "        \n",
    "        # prediction BEFORE-SOFTMAX of the model\n",
    "        self.output = model.predict(self.newimg)\n",
    "        \n",
    "        # distance to the input data\n",
    "        self.l2dist = tf.reduce_sum(tf.square(self.newimg-(tf.tanh(self.timg) * self.boxmul + self.boxplus)),[1,2,3])\n",
    "        \n",
    "        # compute the probability of the label class versus the maximum other\n",
    "        real = tf.reduce_sum((self.tlab)*self.output,1)\n",
    "        other = tf.reduce_max((1-self.tlab)*self.output - (self.tlab*10000),1)\n",
    "\n",
    "        if self.TARGETED:\n",
    "            # if targetted, optimize for making the other class most likely\n",
    "            loss1 = tf.maximum(0.0, other-real+self.CONFIDENCE)\n",
    "        else:\n",
    "            # if untargeted, optimize for making this class least likely.\n",
    "            loss1 = tf.maximum(0.0, real-other+self.CONFIDENCE)\n",
    "\n",
    "        # sum up the losses\n",
    "        self.loss2 = tf.reduce_sum(self.l2dist)\n",
    "        self.loss1 = tf.reduce_sum(self.const*loss1)\n",
    "        self.loss = self.loss1+self.loss2\n",
    "        \n",
    "        # Setup the adam optimizer and keep track of variables we're creating\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        optimizer = tf.train.AdamOptimizer(self.LEARNING_RATE)\n",
    "        self.train = optimizer.minimize(self.loss, var_list=[modifier])\n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "\n",
    "        # these are the variables to initialize when we run\n",
    "        self.setup = []\n",
    "        self.setup.append(self.timg.assign(self.assign_timg))\n",
    "        self.setup.append(self.tlab.assign(self.assign_tlab))\n",
    "        self.setup.append(self.const.assign(self.assign_const))\n",
    "        \n",
    "        self.init = tf.variables_initializer(var_list=[modifier]+new_vars)\n",
    "\n",
    "    def attack(self, imgs, targets):\n",
    "        \"\"\"\n",
    "        Perform the L_2 attack on the given images for the given targets.\n",
    "\n",
    "        If self.targeted is true, then the targets represents the target labels.\n",
    "        If self.targeted is false, then targets are the original class labels.\n",
    "        \"\"\"\n",
    "        r = []\n",
    "        print('go up to',len(imgs))\n",
    "        for i in range(0,len(imgs),self.batch_size):\n",
    "            print('tick',i)\n",
    "            r.extend(self.attack_batch(imgs[i:i+self.batch_size], targets[i:i+self.batch_size]))\n",
    "        return np.array(r)\n",
    "\n",
    "    def attack_batch(self, imgs, labs):\n",
    "        \"\"\"\n",
    "        Run the attack on a batch of images and labels.\n",
    "        \"\"\"\n",
    "        def compare(x,y):\n",
    "            if not isinstance(x, (float, int, np.int64)):\n",
    "                x = np.copy(x)\n",
    "                if self.TARGETED:\n",
    "                    x[y] -= self.CONFIDENCE\n",
    "                else:\n",
    "                    x[y] += self.CONFIDENCE\n",
    "                x = np.argmax(x)\n",
    "            if self.TARGETED:\n",
    "                return x == y\n",
    "            else:\n",
    "                return x != y\n",
    "\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        # convert to tanh-space\n",
    "        imgs = np.arctanh((imgs - self.boxplus) / self.boxmul * 0.999999)\n",
    "\n",
    "        # set the lower and upper bounds accordingly\n",
    "        lower_bound = np.zeros(batch_size)\n",
    "        CONST = np.ones(batch_size)*self.initial_const\n",
    "        upper_bound = np.ones(batch_size)*1e10\n",
    "\n",
    "        # the best l2, score, and image attack\n",
    "        o_bestl2 = [1e10]*batch_size\n",
    "        o_bestscore = [-1]*batch_size\n",
    "        o_bestattack = [np.zeros(imgs[0].shape)]*batch_size\n",
    "        \n",
    "        for outer_step in range(self.BINARY_SEARCH_STEPS):\n",
    "            print(o_bestl2)\n",
    "            # completely reset adam's internal state.\n",
    "            self.sess.run(self.init)\n",
    "            batch = imgs[:batch_size]\n",
    "            batchlab = labs[:batch_size]\n",
    "    \n",
    "            bestl2 = [1e10]*batch_size\n",
    "            bestscore = [-1]*batch_size\n",
    "\n",
    "            # The last iteration (if we run many steps) repeat the search once.\n",
    "            if self.repeat == True and outer_step == self.BINARY_SEARCH_STEPS-1:\n",
    "                CONST = upper_bound\n",
    "\n",
    "            # set the variables so that we don't have to send them over again\n",
    "            self.sess.run(self.setup, {self.assign_timg: batch,\n",
    "                                       self.assign_tlab: batchlab,\n",
    "                                       self.assign_const: CONST})\n",
    "            \n",
    "            prev = np.inf\n",
    "            for iteration in range(self.MAX_ITERATIONS):\n",
    "                # perform the attack \n",
    "                _, l, l2s, scores, nimg = self.sess.run([self.train, self.loss, \n",
    "                                                         self.l2dist, self.output, \n",
    "                                                         self.newimg])\n",
    "\n",
    "                if np.all(scores>=-.0001) and np.all(scores <= 1.0001):\n",
    "                    if np.allclose(np.sum(scores,axis=1), 1.0, atol=1e-3):\n",
    "                        if not self.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK:\n",
    "                            raise Exception(\"The output of model.predict should return the pre-softmax layer. It looks like you are returning the probability vector (post-softmax). If you are sure you want to do that, set attack.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK = True\")\n",
    "                \n",
    "                # print out the losses every 10%\n",
    "                if iteration%(self.MAX_ITERATIONS//10) == 0:\n",
    "                    print(iteration,self.sess.run((self.loss,self.loss1,self.loss2)))\n",
    "\n",
    "                # check if we should abort search if we're getting nowhere.\n",
    "                if self.ABORT_EARLY and iteration%(self.MAX_ITERATIONS//10) == 0:\n",
    "                    if l > prev*.9999:\n",
    "                        break\n",
    "                    prev = l\n",
    "\n",
    "                # adjust the best result found so far\n",
    "                for e,(l2,sc,ii) in enumerate(zip(l2s,scores,nimg)):\n",
    "                    if l2 < bestl2[e] and compare(sc, np.argmax(batchlab[e])):\n",
    "                        bestl2[e] = l2\n",
    "                        bestscore[e] = np.argmax(sc)\n",
    "                    if l2 < o_bestl2[e] and compare(sc, np.argmax(batchlab[e])):\n",
    "                        o_bestl2[e] = l2\n",
    "                        o_bestscore[e] = np.argmax(sc)\n",
    "                        o_bestattack[e] = ii\n",
    "\n",
    "            # adjust the constant as needed\n",
    "            for e in range(batch_size):\n",
    "                if compare(bestscore[e], np.argmax(batchlab[e])) and bestscore[e] != -1:\n",
    "                    # success, divide const by two\n",
    "                    upper_bound[e] = min(upper_bound[e],CONST[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        CONST[e] = (lower_bound[e] + upper_bound[e])/2\n",
    "                else:\n",
    "                    # failure, either multiply by 10 if no solution found yet\n",
    "                    #          or do binary search with the known upper bound\n",
    "                    lower_bound[e] = max(lower_bound[e],CONST[e])\n",
    "                    if upper_bound[e] < 1e9:\n",
    "                        CONST[e] = (lower_bound[e] + upper_bound[e])/2\n",
    "                    else:\n",
    "                        CONST[e] *= 10\n",
    "\n",
    "        # return the best solution found\n",
    "        o_bestl2 = np.array(o_bestl2)\n",
    "        return o_bestattack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test_attack.py -- sample code to test attack procedure\n",
    "##\n",
    "## Copyright (C) 2016, Nicholas Carlini <nicholas@carlini.com>.\n",
    "##\n",
    "## This program is licenced under the BSD 2-Clause licence,\n",
    "## contained in the LICENCE file in this directory.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# from setup_cifar import CIFAR, CIFARModel\n",
    "# from setup_mnist import MNIST, MNISTModel\n",
    "# from setup_inception import ImageNet, InceptionModel\n",
    "\n",
    "# from l2_attack import CarliniL2\n",
    "# from l0_attack import CarliniL0\n",
    "# from li_attack import CarliniLi\n",
    "\n",
    "\n",
    "def show(img):\n",
    "    \"\"\"\n",
    "    Show MNSIT digits in the console.\n",
    "    \"\"\"\n",
    "    remap = \"  .*#\"+\"#\"*100\n",
    "    img = (img.flatten()+.5)*3\n",
    "    if len(img) != 784: return\n",
    "    print(\"START\")\n",
    "    for i in range(28):\n",
    "        print(\"\".join([remap[int(round(x))] for x in img[i*28:i*28+28]]))\n",
    "\n",
    "\n",
    "def generate_data(data, samples, targeted=True, start=0, inception=False):\n",
    "    \"\"\"\n",
    "    Generate the input data to the attack algorithm.\n",
    "\n",
    "    data: the images to attack\n",
    "    samples: number of samples to use\n",
    "    targeted: if true, construct targeted attacks, otherwise untargeted attacks\n",
    "    start: offset into data to use\n",
    "    inception: if targeted and inception, randomly sample 100 targets intead of 1000\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(samples):\n",
    "        if targeted:\n",
    "            if inception:\n",
    "                seq = random.sample(range(1,1001), 10)\n",
    "            else:\n",
    "                # data.test_labels.shape[1] will have the number of classes (e.g., 10 for MNIST)\n",
    "                # range would gives us 0,1,2,3,....9 for MNIST\n",
    "                seq = range(data.test_labels.shape[1])\n",
    "\n",
    "            # for every class (e.g., 0 to 9 in MNIST)\n",
    "            for j in seq:\n",
    "                # When samples==1, then we will put the image at test_data[0] (because start+i will be 0)\n",
    "                # to inputs 9 times, i.e., inputs[0] through inputs[8] will contain data.test_data[0].\n",
    "                # These will serve as the source image. We will be converting this image to adv examples\n",
    "                # targeting each of the other 9 classes\n",
    "                # When j == the label of the data.test_data[0]-th image, we skip adding anything to \n",
    "                # inputs or targets. \n",
    "                \n",
    "                if (j == np.argmax(data.test_labels[start+i])) and (inception == False):\n",
    "                    print('CONTINUE for j={} label={}'.format(j, np.argmax(data.test_labels[start+i])))\n",
    "                    continue\n",
    "                inputs.append(data.test_data[start+i])\n",
    "                \n",
    "                # add a one-hot encoded row that has a 1 at j-th column\n",
    "                targets.append(np.eye(data.test_labels.shape[1])[j])\n",
    "        else:\n",
    "            inputs.append(data.test_data[start+i])\n",
    "            targets.append(data.test_labels[start+i])\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data and model\n",
      "Test data shape:  (10000, 10)\n",
      "generating data using the test data.\n",
      "CONTINUE for j=7 label=7\n",
      "go up to 9\n",
      "tick 0\n",
      "[10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0]\n",
      "0 (0.2918651, 0.28326344, 0.00860168)\n",
      "100 (0.28463978, 0.28443655, 0.00020322186)\n",
      "200 (0.28463963, 0.28443637, 0.00020326595)\n",
      "[10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0]\n",
      "0 (2.8412926, 2.8326058, 0.008686714)\n",
      "100 (2.8276167, 2.8073277, 0.020288987)\n",
      "200 (2.8275518, 2.8070781, 0.020473607)\n",
      "[10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0]\n",
      "0 (28.33473, 28.326033, 0.008696749)\n",
      "100 (26.520996, 24.801777, 1.719219)\n",
      "200 (26.424667, 24.436512, 1.9881561)\n",
      "300 (25.04134, 21.092003, 3.949337)\n",
      "400 (24.880047, 20.747892, 4.1321554)\n",
      "500 (24.863167, 20.713129, 4.1500373)\n",
      "600 (24.85767, 20.698553, 4.159116)\n",
      "700 (24.854944, 20.688349, 4.166596)\n",
      "800 (24.854353, 20.68652, 4.1678333)\n",
      "[10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0, 10000000000.0]\n",
      "0 (283.26898, 283.26028, 0.008697774)\n",
      "100 (178.6207, 141.81274, 36.807945)\n",
      "200 (124.842155, 50.94896, 73.893196)\n",
      "300 (72.00224, 10.383625, 61.61862)\n",
      "400 (53.93701, 3.7793036, 50.157707)\n",
      "500 (49.69114, 2.9004495, 46.79069)\n",
      "600 (47.39101, 2.4426281, 44.948383)\n",
      "700 (46.202343, 1.327045, 44.875298)\n",
      "800 (45.606274, 1.0635781, 44.542694)\n",
      "900 (45.392548, 0.97573745, 44.41681)\n",
      "[4.54213, 10000000000.0, 4.28815, 3.3110802, 10000000000.0, 4.6004634, 10000000000.0, 5.1742764, 3.617725]\n",
      "0 (1035.4186, 1035.4099, 0.0086977575)\n",
      "100 (538.68286, 500.26282, 38.42004)\n",
      "200 (223.79755, 143.73547, 80.06207)\n",
      "300 (96.181526, 7.0915294, 89.09)\n",
      "400 (76.33671, 0.43353847, 75.90317)\n",
      "500 (67.38717, 0.11700305, 67.270164)\n",
      "600 (61.38771, 0.15717879, 61.230534)\n",
      "700 (57.89776, 0.5165054, 57.381252)\n",
      "800 (55.215435, 0.4064391, 54.808994)\n",
      "900 (53.24652, 0.07643108, 53.17009)\n",
      "[4.267083, 9.640373, 4.141118, 2.89842, 6.7893906, 4.574049, 10.101065, 5.1742764, 3.5996482]\n",
      "0 (573.7632, 573.75446, 0.008697665)\n",
      "100 (316.3249, 286.63742, 29.68747)\n",
      "200 (159.24084, 98.207214, 61.033634)\n",
      "300 (88.210785, 16.941387, 71.269394)\n",
      "400 (68.29465, 7.102083, 61.192562)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-a50c5951d0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                                     start=0, inception=False)\n\u001b[1;32m     16\u001b[0m     \u001b[0mtimestart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0madv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtimeend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9ad947df4c65>\u001b[0m in \u001b[0;36mattack\u001b[0;34m(self, imgs, targets)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tick'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9ad947df4c65>\u001b[0m in \u001b[0;36mattack_batch\u001b[0;34m(self, imgs, labs)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 _, l, l2s, scores, nimg = self.sess.run([self.train, self.loss, \n\u001b[1;32m    195\u001b[0m                                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                                                          self.newimg])\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.0001\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# continued from previous cell\n",
    "# main method in test_attack.py\n",
    "with tf.Session() as sess:\n",
    "    print('Loading the data and model')\n",
    "    data, model =  MNIST(), MNISTModel(\"models/mnist\", sess)\n",
    "    #data, model =  CIFAR(), CIFARModel(\"models/cifar\", sess)\n",
    "    attack = CarliniL2(sess, model, batch_size=9, max_iterations=1000, confidence=0)\n",
    "    #attack = CarliniL0(sess, model, max_iterations=1000, initial_const=10,\n",
    "    #                   largest_const=15)\n",
    "\n",
    "    print('Test data shape: ', data.test_labels.shape)\n",
    "    \n",
    "    print('generating data using the test data.')\n",
    "    inputs, targets = generate_data(data, samples=1, targeted=True,\n",
    "                                    start=0, inception=False)\n",
    "    \n",
    "    print('inputs shape: ', inputs.shape)\n",
    "    print('targets shape: ', targets.shape)\n",
    "    \n",
    "    timestart = time.time()\n",
    "    adv = attack.attack(inputs, targets)\n",
    "    timeend = time.time()\n",
    "    \n",
    "    print(\"Took\",timeend-timestart,\"seconds to run\",len(inputs),\"samples.\")\n",
    "    print('adv shape:', adv.shape)\n",
    "    \n",
    "    for i in range(len(adv)):\n",
    "        print(\"Valid:\")\n",
    "        show(inputs[i])\n",
    "        print(\"Adversarial:\")\n",
    "        show(adv[i])\n",
    "\n",
    "        print(\"Classification:\", model.model.predict(adv[i:i+1]))\n",
    "\n",
    "        print(\"Total distortion:\", np.sum((adv[i]-inputs[i])**2)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182e79b438>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADa9JREFUeJzt3X2MXPV1xvHnib1e4jW0OMTGNQYnhKA4NJBqYxK5rRxRp9AEmSiBYqmWK6UsakGCKmqLLEVBaptSFEJpk0ZyihsT8ZYGKFbipkFWW4pKHS+Id9NCqUtcb72AaW0C+AWf/rHX0QZ2fjvM2531+X4ka2buuXfu0fU+e2f2N3d+jggByOcddTcAoB6EH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUrN7ubM5HozjNNTLXQKpvK4f62AccDPrthV+2+dLuknSLEl/FRHXldY/TkM61+e1s0sABdtia9Prtvyy3/YsSV+TdIGkZZLW2F7W6vMB6K123vMvl/RsRDwXEQcl3SFpdWfaAtBt7YR/saQfTXq8q1r2U2yP2B61PXpIB9rYHYBOaif8U/1R4S3XB0fEhogYjojhAQ22sTsAndRO+HdJWjLp8SmSdrfXDoBeaSf82yWdYfs9tudIulTS5s60BaDbWh7qi4jDtq+U9PeaGOrbGBFPdqwzAF3V1jh/RGyRtKVDvQDoIT7eCyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJtzdJre6ek/ZLekHQ4IoY70RSA7msr/JWPR8SLHXgeAD3Ey34gqXbDH5J+YPsh2yOdaAhAb7T7sn9FROy2vUDSfbafjoj7J69Q/VIYkaTjNLfN3QHolLbO/BGxu7odl3SPpOVTrLMhIoYjYnhAg+3sDkAHtRx+20O2jz96X9InJD3RqcYAdFc7L/sXSrrH9tHnuS0ivt+RrgB0Xcvhj4jnJJ3dwV4A9BBDfUBShB9IivADSRF+ICnCDyRF+IGkOnFVXwovXfaxhrVT1z5b3Pbp8YXF+sEDA8X64tvL9bm7XmlYO/LIU8VtkRdnfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IinH+Jv3+793WsPaZoZfLG5/e5s5Xlss7D7/asHbTCx9vc+cz1w/HT2tYG7rhZ4rbzt76UKfb6Tuc+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKUdEz3Z2gufHuT6vZ/vrpB9/9tyGtRc/VP4deuKO8jF++QMu1ud86H+L9evPurthbdU7Xytu+71X5xXrn5zb+LsC2vVaHCzWtx0YKtZXHneo5X2/73uXF+vvH9ne8nPXaVts1b7YW/6BqnDmB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkpr2e3/ZGSZ+SNB4RZ1XL5ku6U9JSSTslXRIR01zUPrMNfWdbodbec5/Q3ub6i5NXNqz90Yql5X3/U3nOgetXvq+Fjpoz+7UjxfrQY2PF+rvuv6tY//k5jec7mLuzPBdCBs2c+b8p6fw3LbtG0taIOEPS1uoxgBlk2vBHxP2S9r5p8WpJm6r7myRd1OG+AHRZq+/5F0bEmCRVtws61xKAXuj6d/jZHpE0IknHaW63dwegSa2e+ffYXiRJ1e14oxUjYkNEDEfE8IAGW9wdgE5rNfybJa2r7q+TdG9n2gHQK9OG3/btkh6UdKbtXbY/J+k6SatsPyNpVfUYwAwy7Xv+iFjToDQzL8w/Bh3+nz0Na0N3Na5J0hvTPPfQd15qoaPO2PNbHyvWPzin/OP75b1nNqwt/evnitseLlaPDXzCD0iK8ANJEX4gKcIPJEX4gaQIP5AUU3SjNrNPW1Ksf3X9V4v1Ac8q1v/mpl9pWHvX2IPFbTPgzA8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHOj9o8/buLi/WPDJZnmn7yYHn68flPvfq2e8qEMz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJMU4P7rqwCc/0rD28GdvnGbr8gxPv33VVcX6O//lh9M8f26c+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqWnH+W1vlPQpSeMRcVa17FpJl0l6oVptfURs6VaTmLmev6Dx+WWey+P4a/5zVbE+9/uPFutRrKKZM/83JZ0/xfIbI+Kc6h/BB2aYacMfEfdL2tuDXgD0UDvv+a+0/ZjtjbZP7FhHAHqi1fB/XdLpks6RNCbphkYr2h6xPWp79JAOtLg7AJ3WUvgjYk9EvBERRyR9Q9LywrobImI4IoYHprlQA0DvtBR+24smPfy0pCc60w6AXmlmqO92SSslnWR7l6QvSlpp+xxNjKbslHR5F3sE0AXThj8i1kyx+OYu9IIZ6B3HH1+sr/2lBxrW9h15vbjt+JfeW6wPHtherKOMT/gBSRF+ICnCDyRF+IGkCD+QFOEHkuKru9GWZ679YLH+3ZP+smFt9TOfKW47uIWhvG7izA8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHOj6L/+42PFuuP/fqfF+v/cfhQw9orf3pKcdtBjRXraA9nfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IinH+5GYv/rli/eov3FmsD7r8I3Tpo2sb1t79d1yvXyfO/EBShB9IivADSRF+ICnCDyRF+IGkCD+Q1LTj/LaXSLpF0smSjkjaEBE32Z4v6U5JSyXtlHRJRLzcvVbRCs8u/xef/d1dxfrF814q1m/dv6BYX/iFxueXI8Ut0W3NnPkPS/p8RHxA0kclXWF7maRrJG2NiDMkba0eA5ghpg1/RIxFxMPV/f2SdkhaLGm1pE3VapskXdStJgF03tt6z297qaQPS9omaWFEjEkTvyAklV//AegrTYff9jxJd0m6OiL2vY3tRmyP2h49pAOt9AigC5oKv+0BTQT/1oi4u1q8x/aiqr5I0vhU20bEhogYjojhAQ12omcAHTBt+G1b0s2SdkTEVyaVNktaV91fJ+nezrcHoFuauaR3haS1kh63/Ui1bL2k6yR92/bnJD0v6eLutIi2nH1msfyHC77V1tN/7Uvl//afffTBtp4f3TNt+CPiAUluUD6vs+0A6BU+4QckRfiBpAg/kBThB5Ii/EBShB9Iiq/uPgbMWvb+hrWRO9r77NWyjVcU60u/9a9tPT/qw5kfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JinP8Y8PTvnNiwduHcpr9xbUqn/OPB8goRbT0/6sOZH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSYpx/Bnj9wuXF+tYLbyhU53a2GRwzOPMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFLTjvPbXiLpFkknSzoiaUNE3GT7WkmXSXqhWnV9RGzpVqOZ7V4xq1g/dXbrY/m37l9QrA/sK1/Pz9X8M1czH/I5LOnzEfGw7eMlPWT7vqp2Y0R8uXvtAeiWacMfEWOSxqr7+23vkLS4240B6K639Z7f9lJJH5a0rVp0pe3HbG+0PeV3SdkesT1qe/SQDrTVLIDOaTr8tudJukvS1RGxT9LXJZ0u6RxNvDKY8gPmEbEhIoYjYnhAgx1oGUAnNBV+2wOaCP6tEXG3JEXEnoh4IyKOSPqGpPLVJwD6yrTht21JN0vaERFfmbR80aTVPi3pic63B6Bbmvlr/wpJayU9bvuRatl6SWtsn6OJ0Z6dki7vSodoy5+8tKxYf/BXlxbrMfZ4B7tBP2nmr/0PSPIUJcb0gRmMT/gBSRF+ICnCDyRF+IGkCD+QFOEHknL0cIrlEzw/zvV5PdsfkM222Kp9sXeqofm34MwPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0n1dJzf9guS/mvSopMkvdizBt6efu2tX/uS6K1VnezttIh4dzMr9jT8b9m5PRoRw7U1UNCvvfVrXxK9taqu3njZDyRF+IGk6g7/hpr3X9KvvfVrXxK9taqW3mp9zw+gPnWf+QHUpJbw2z7f9r/Zftb2NXX00IjtnbYft/2I7dGae9loe9z2E5OWzbd9n+1nqtspp0mrqbdrbf93dewesf1rNfW2xPY/2N5h+0nbV1XLaz12hb5qOW49f9lve5akf5e0StIuSdslrYmIp3raSAO2d0oajojax4Rt/7KkVyTdEhFnVcuul7Q3Iq6rfnGeGBF/0Ce9XSvplbpnbq4mlFk0eWZpSRdJ+k3VeOwKfV2iGo5bHWf+5ZKejYjnIuKgpDskra6hj74XEfdL2vumxaslbarub9LED0/PNeitL0TEWEQ8XN3fL+nozNK1HrtCX7WoI/yLJf1o0uNd6q8pv0PSD2w/ZHuk7mamsLCaNv3o9OkLau7nzaadubmX3jSzdN8cu1ZmvO60OsI/1VcM9dOQw4qI+AVJF0i6onp5i+Y0NXNzr0wxs3RfaHXG606rI/y7JC2Z9PgUSbtr6GNKEbG7uh2XdI/6b/bhPUcnSa1ux2vu5yf6aebmqWaWVh8cu36a8bqO8G+XdIbt99ieI+lSSZtr6OMtbA9Vf4iR7SFJn1D/zT68WdK66v46SffW2MtP6ZeZmxvNLK2aj12/zXhdy4d8qqGMP5M0S9LGiPjjnjcxBdvv1cTZXpqYxPS2OnuzfbuklZq46muPpC9K+ltJ35Z0qqTnJV0cET3/w1uD3lZq4qXrT2ZuPvoeu8e9/aKkf5b0uKQj1eL1mnh/XduxK/S1RjUcNz7hByTFJ/yApAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyT1//RJwTziTb07AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182df37b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(inputs[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182d2d4dd8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182d94d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
